---
title: "Choice-Based Conjoint Analysis: OTT Streaming Platforms"
subtitle: "Data Exploration, Cleaning & CBC Estimation"
author: "Group X: Laura Pérez, Likitha Yenuga, Ishika Narang, Yu Hsun Fang, Jonah Paige, Santiago Sierra"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: false
    toc_depth: 3
    number_sections: true
    code_folding: hide
    theme: flatly
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  fig.width = 10,
  fig.height = 6
)
```

# R Setup

```{r packages}
if (!require("pacman")) {
  install.packages("pacman")
  library("pacman")
}

pacman::p_load(
  "tidyverse",
  "readxl",
  "janitor",
  "scales",
  "knitr",
  "kableExtra",
  "lubridate",
  "fastDummies",
  "mlogit",
  "gmnl",
  "ChoiceModelR"
)
```

# Introduction

This report documents our CBC analysis of consumer preferences for OTT streaming platforms. It covers the full pipeline: data exploration and cleaning, MNL and HB-MNL estimation, predictive validation, part-worth utilities, WTP, and market simulations.

## CBC Design Overview

| Design Element | Specification |
|:---|:---|
| Conjoint Method | Choice-Based Conjoint (CBC) |
| Design Type | Random (computer-generated via Discover) |
| Choice Tasks per Respondent | 10 |
| Alternatives per Task | 3 streaming profiles + 1 "None" option |
| Holdout Tasks | 1 (fixed, for validation) |

## Attributes and Levels

```{r attributes-table}
attr_df <- data.frame(
  Attribute = c(
    rep("Monthly Price", 5), rep("Ads", 3), rep("Video Quality", 3),
    rep("Simultaneous Streams", 3), rep("Content Type", 3)
  ),
  Level = c(
    "€4.99", "€7.99", "€9.99", "€12.99", "€14.99",
    "With Ads", "Limited Ads (before content)", "Ad-free",
    "HD (720p)", "Full HD (1080p)", "4K + HDR",
    "1 screen", "2 screens", "4 screens",
    "Licensed Content Only", "Originals & Licensed", "Exclusive Originals Only"
  ),
  Code = c(
    "1", "2", "3", "4", "5",
    "1", "2", "3",
    "1", "2", "3",
    "1", "2", "3",
    "1", "2", "3"
  )
)

attr_df %>%
  kable(caption = "CBC Attributes, Levels, and Design Codes") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  collapse_rows(columns = 1, valign = "top")
```

Full factorial: $5 \times 3 \times 3 \times 3 \times 3 = 405$ possible profiles.

# Data Loading

```{r load-data}
# Respondent-level survey data
raw_all     <- read_excel("CPM Survey - Respondent Data.xlsx", sheet = "All Data")
raw_utils   <- read_excel("CPM Survey - Respondent Data.xlsx", sheet = "Rescaled - CBC - Random")
raw_imports <- read_excel("CPM Survey - Respondent Data.xlsx", sheet = "Importances - CBC - Random")

# Long-format CBC design with attribute codes and choices
design_raw  <- read_excel("CPM Survey - CBC - Random Design & choices.xlsx",
                          sheet = "Design & Choices")
```

```{r sheet-summary}
data.frame(
  Source = c("All Data", "Rescaled Utilities", "Importances", "Design & Choices"),
  Rows = c(nrow(raw_all), nrow(raw_utils), nrow(raw_imports), nrow(design_raw)),
  Columns = c(ncol(raw_all), ncol(raw_utils), ncol(raw_imports), ncol(design_raw)),
  Description = c(
    "Survey responses (demographics, usage, CBC choices, segments)",
    "Individual-level HB rescaled part-worth utilities",
    "Individual-level attribute importance scores",
    "Long-format experimental design with attribute codes and responses"
  )
) %>%
  kable(caption = "Data Sources Overview") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

# Data Cleaning

## Survey Data

Row 1 of "All Data" contains survey question text (not a respondent). We remove it and clean variables.

```{r clean-survey}
survey <- raw_all[-1, ] %>%
  rename(
    record_id       = `Record ID`,
    status          = `Respondent Status`,
    start_time      = `Start Time (UTC)`,
    end_time        = `End Time (UTC)`,
    gender          = Gender,
    age             = Age,
    employment      = `Employment Status`,
    education       = Education,
    income          = Income,
    ott_use         = `Use of OTT?`,
    n_subscriptions = `Number of Subscriptions`,
    platform_netflix = `Platforms currently in use_Netflix`,
    platform_disney  = `Platforms currently in use_Disney+`,
    platform_amazon  = `Platforms currently in use_Amazon Prime`,
    platform_hbo     = `Platforms currently in use_HBO Max`,
    platform_apple   = `Platforms currently in use_Apple TV+`,
    platform_other   = `Platforms currently in use_Other(s):`,
    spending        = Spending,
    hours_ott       = `Hours spent on OTT`,
    holdout         = `Holdout Question`
  ) %>%
  mutate(
    age             = as.numeric(age),
    n_subscriptions = as.numeric(n_subscriptions),
    gender          = as.factor(gender),
    elapsed_minutes = as.numeric(difftime(end_time, start_time, units = "mins")),
    across(starts_with("platform_"), ~ ifelse(is.na(.), 0L, 1L))
  )

# Rename CBC task columns
for (i in 1:10) {
  names(survey)[names(survey) == paste0("CBC - Random_", i)] <- paste0("cbc_task_", i)
}
survey <- survey %>%
  mutate(across(starts_with("cbc_task_"), ~ as.integer(.x)))

cat("Respondents:", nrow(survey), "\n")
cat("Unique IDs:", length(unique(survey$record_id)), "\n")
cat("Duplicates:", sum(duplicated(survey$record_id)), "\n")
```

## Design Data

The design file contains the full CBC experiment in long format: one row per alternative per task per respondent, with integer-coded attribute levels and a binary response indicator.

```{r inspect-design}
cat("Design rows:", nrow(design_raw), "\n")
cat("Respondents in design:", length(unique(design_raw$`Record ID`)), "\n")
cat("Tasks:", length(unique(design_raw$Task)), "\n")
cat("Concepts per task:", length(unique(design_raw$Concept)), "\n")

head(design_raw, 8)
```

```{r check-design-respondents}
# One respondent in survey has no design data
missing_from_design <- setdiff(survey$record_id, design_raw$`Record ID`)
cat("Respondents missing from design file:", length(missing_from_design), "\n")
if (length(missing_from_design) > 0) cat("  ID:", missing_from_design, "\n")
```

We restrict the analysis to the **105 respondents** present in both datasets.

```{r prepare-cbc}
# Rename design columns
cbc <- design_raw %>%
  rename(
    record_id = `Record ID`,
    task      = Task,
    alt       = Concept,
    price_code     = `Monthly Price`,
    ads_code       = Ads,
    quality_code   = `Video Quality`,
    streams_code   = `Simultaneous Streams`,
    content_code   = `Content Type`,
    choice         = Response
  )

# Map integer codes to actual attribute values
price_map   <- c(`1` = 4.99, `2` = 7.99, `3` = 9.99, `4` = 12.99, `5` = 14.99)
ads_map     <- c(`1` = "With Ads", `2` = "Limited Ads", `3` = "Ad-free")
quality_map <- c(`1` = "HD 720p", `2` = "Full HD 1080p", `3` = "4K HDR")
streams_map <- c(`1` = "1 screen", `2` = "2 screens", `3` = "4 screens")
content_map <- c(`1` = "Licensed Only", `2` = "Originals & Licensed", `3` = "Exclusive Originals")

cbc <- cbc %>%
  mutate(
    # Numeric price (0 for None)
    Price = ifelse(price_code == 0, 0, price_map[as.character(price_code)]),
    # NONE indicator
    NONE = as.integer(alt == 4),
    # Create numeric respondent id
    id = as.integer(factor(record_id, levels = unique(record_id)))
  )

cat("CBC data dimensions:", nrow(cbc), "rows x", ncol(cbc), "cols\n")
cat("Respondents:", length(unique(cbc$id)), "\n")
cat("Total choice sets:", nrow(cbc) / 4, "\n")
cat("Choices (Response=1):", sum(cbc$choice), "\n")
```

## Verify Data Integrity

```{r verify-integrity}
# Exactly one choice per choice set
choices_per_set <- cbc %>%
  group_by(id, task) %>%
  summarise(n_chosen = sum(choice), .groups = "drop")

cat("All choice sets have exactly 1 choice:",
    all(choices_per_set$n_chosen == 1), "\n")

# None option always in alt = 4 with all codes = 0
none_rows <- cbc %>% filter(NONE == 1)
cat("None rows always have zero attribute codes:",
    all(none_rows$price_code == 0 &
        none_rows$ads_code == 0 &
        none_rows$quality_code == 0 &
        none_rows$streams_code == 0 &
        none_rows$content_code == 0), "\n")
```

# Response Quality Assessment

## Completion Times

```{r completion-times}
survey %>%
  ggplot(aes(x = elapsed_minutes)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white", alpha = 0.8) +
  geom_vline(xintercept = median(survey$elapsed_minutes, na.rm = TRUE),
    linetype = "dashed", color = "darkred", linewidth = 0.8) +
  annotate("text",
    x = median(survey$elapsed_minutes, na.rm = TRUE) + 1,
    y = Inf, vjust = 2, hjust = 0,
    label = paste0("Median: ", round(median(survey$elapsed_minutes, na.rm = TRUE), 1), " min"),
    color = "darkred", fontface = "bold") +
  scale_x_continuous(breaks = seq(0, 30, 2), limits = c(0, 30)) +
  labs(title = "Distribution of Survey Completion Times",
       subtitle = "Excluding extreme outliers (>30 min)",
       x = "Elapsed Time (minutes)", y = "Count") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        axis.text = element_text(color = "black"))
```

## Quality Flags and Respondent Removal

We identify low-quality respondents using the following criteria:

- **Speeders**: completed in under 3 minutes
- **Straight-liners**: chose the same alternative in 8 or more of 10 tasks
- **Removal criterion**: only respondents who are **both** speeders AND straight-liners are removed. Fast completers with varied response patterns are kept, and non-subscribers who consistently chose "None" are kept (rational opt-out).

```{r quality-flags}
# Match survey to design respondents
survey_matched <- survey %>% filter(record_id %in% unique(cbc$record_id))

survey_matched <- survey_matched %>%
  mutate(
    none_count = rowSums(across(starts_with("cbc_task_"), ~ .x == 4)),
    same_choice_count = apply(
      select(., starts_with("cbc_task_")), 1,
      function(x) max(table(x))
    ),
    flag_speeder       = elapsed_minutes < 3,
    flag_straightliner = same_choice_count >= 8,
    # Remove ONLY if both speeder AND straightliner
    flag_remove        = flag_speeder & flag_straightliner
  )

data.frame(
  Flag = c("Speeders (<3 min)", "Straight-liners (≥8 same)",
           "Speeder AND Straight-liner (removed)",
           "Retained respondents"),
  Count = c(
    sum(survey_matched$flag_speeder),
    sum(survey_matched$flag_straightliner),
    sum(survey_matched$flag_remove),
    sum(!survey_matched$flag_remove)
  )
) %>%
  kable(caption = "Response Quality Assessment (n=105)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r show-removed}
removed <- survey_matched %>% filter(flag_remove)
if (nrow(removed) > 0) {
  removed %>%
    select(record_id, elapsed_minutes, same_choice_count, none_count, gender, age) %>%
    mutate(elapsed_minutes = round(elapsed_minutes, 1)) %>%
    kable(
      caption = "Removed Respondents (Speeder + Straight-liner)",
      col.names = c("Record ID", "Minutes", "Max Same Choice", "None Count", "Gender", "Age")
    ) %>%
    kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
}
```

```{r apply-removal}
# Remove flagged respondents from both survey and CBC design data
ids_to_remove <- survey_matched %>% filter(flag_remove) %>% pull(record_id)
survey_matched <- survey_matched %>% filter(!flag_remove)
cbc <- cbc %>% filter(!record_id %in% ids_to_remove)

cat("Respondents after removal:", nrow(survey_matched), "\n")
cat("CBC rows after removal:", nrow(cbc), "\n")
cat("Respondents in CBC:", length(unique(cbc$id)), "\n")

# Reassign numeric IDs after removal
cbc <- cbc %>%
  mutate(id = as.integer(factor(record_id, levels = unique(record_id))))
```

> We apply a conservative removal criterion (both conditions must hold) to preserve sample size. Respondents who completed quickly but varied their answers likely engaged with the task. Non-subscribers choosing "None" consistently reflect a legitimate preference, not inattention.

# Respondent Demographics

```{r gender-plot}
survey_matched %>%
  count(gender) %>%
  mutate(pct = round(n / sum(n) * 100, 1)) %>%
  ggplot(aes(x = gender, y = n, fill = gender)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(n, " (", pct, "%)")),
    vjust = -0.5, fontface = "bold", size = 4) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Gender Distribution", x = "", y = "Count") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        legend.position = "none",
        axis.text = element_text(color = "black"))
```

```{r age-plot}
survey_matched %>%
  ggplot(aes(x = age)) +
  geom_histogram(bins = 20, fill = "steelblue", color = "white", alpha = 0.8) +
  geom_vline(xintercept = median(survey_matched$age, na.rm = TRUE),
    linetype = "dashed", color = "darkred", linewidth = 0.8) +
  annotate("text",
    x = median(survey_matched$age, na.rm = TRUE) + 1.5,
    y = Inf, vjust = 2, hjust = 0,
    label = paste0("Median: ", median(survey_matched$age, na.rm = TRUE)),
    color = "darkred", fontface = "bold") +
  labs(title = "Age Distribution", x = "Age", y = "Count") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        axis.text = element_text(color = "black"))
```

```{r employment-income, fig.height=5}
p1 <- survey_matched %>%
  count(employment) %>%
  mutate(pct = round(n / sum(n) * 100, 1), employment = fct_reorder(employment, n)) %>%
  ggplot(aes(x = n, y = employment)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.8) +
  geom_text(aes(label = paste0(n, " (", pct, "%)")), hjust = -0.1, size = 3.5) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.3))) +
  labs(title = "Employment Status", x = "Count", y = "") +
  theme_bw(base_size = 12) +
  theme(plot.title = element_text(face = "bold"))

p2 <- survey_matched %>%
  count(income) %>%
  mutate(
    pct = round(n / sum(n) * 100, 1),
    income = factor(income, levels = c(
      "Less than €1499", "€1500 - €2499", "€2500 - €3499",
      "€3500 - €4999", "More than €5000"
    ))
  ) %>%
  filter(!is.na(income)) %>%
  ggplot(aes(x = income, y = n, fill = income)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(n, " (", pct, "%)")), vjust = -0.5, size = 3.5) +
  scale_fill_brewer(palette = "Pastel1") +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 12)) +
  labs(title = "Monthly Net Income", x = "", y = "Count") +
  theme_bw(base_size = 12) +
  theme(plot.title = element_text(face = "bold"), legend.position = "none")

p1
p2
```

> The sample is predominantly young (median age `r median(survey_matched$age, na.rm = TRUE)`), consisting mostly of students and early-career professionals with low-to-moderate incomes — typical of a university convenience sample.

# OTT Usage Patterns

```{r ott-use}
survey_matched %>%
  count(ott_use) %>%
  mutate(pct = round(n / sum(n) * 100, 1), ott_use = fct_reorder(ott_use, n)) %>%
  ggplot(aes(x = n, y = ott_use, fill = ott_use)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(n, " (", pct, "%)")),
    hjust = -0.1, fontface = "bold", size = 4) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.3))) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "OTT Subscription Status", x = "Count", y = "") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"), legend.position = "none")
```

```{r platform-usage}
data.frame(
  Platform = c("Netflix", "Disney+", "Amazon Prime", "HBO Max", "Apple TV+", "Other"),
  Users = c(
    sum(survey_matched$platform_netflix), sum(survey_matched$platform_disney),
    sum(survey_matched$platform_amazon), sum(survey_matched$platform_hbo),
    sum(survey_matched$platform_apple), sum(survey_matched$platform_other)
  )
) %>%
  mutate(Pct = round(Users / nrow(survey_matched) * 100, 1),
         Platform = fct_reorder(Platform, Users)) %>%
  ggplot(aes(x = Users, y = Platform, fill = Platform)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(Users, " (", Pct, "%)")),
    hjust = -0.1, fontface = "bold", size = 4) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.3))) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Platform Usage", x = "Number of Users", y = "") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"), legend.position = "none")
```

# Correlation Analysis

Before model estimation, we test a few associations between respondent characteristics and their CBC choices.

## Higher Price Choices vs Income

Do higher-income respondents tend to choose more expensive streaming options? We compute the average price of each respondent's chosen alternatives (excluding "None" choices) and correlate it with income.

```{r corr-price-income}
# Compute average chosen price per respondent
avg_chosen_price <- cbc %>%
  filter(choice == 1 & NONE == 0) %>%
  group_by(record_id) %>%
  summarise(avg_price = mean(Price), n_real_choices = n(), .groups = "drop")

# Map income to ordinal numeric
income_order <- c(
  "Less than €1499" = 1,
  "€1500 - €2499" = 2,
  "€2500 - €3499" = 3,
  "€3500 - €4999" = 4,
  "More than €5000"  = 5
)

corr_price_income <- survey_matched %>%
  select(record_id, income) %>%
  mutate(income_num = income_order[as.character(income)]) %>%
  inner_join(avg_chosen_price, by = "record_id") %>%
  filter(!is.na(income_num))

cor_val <- round(cor(corr_price_income$income_num,
                     corr_price_income$avg_price,
                     use = "complete.obs"), 3)

income_labels <- c(`1` = "<€1.5k", `2` = "€1.5-2.5k", `3` = "€2.5-3.5k",
                    `4` = "€3.5-5k", `5` = "€5k+")

corr_price_income %>%
  mutate(income_label = income_labels[as.character(income_num)]) %>%
  ggplot(aes(x = reorder(income_label, income_num), y = avg_price)) +
  geom_boxplot(fill = "steelblue", alpha = 0.6) +
  geom_jitter(width = 0.15, alpha = 0.4, size = 2) +
  annotate("text", x = 1, y = max(corr_price_income$avg_price) + 0.3,
    label = paste0("Spearman r = ", cor_val), hjust = 0,
    fontface = "italic", size = 4, color = "darkred") +
  labs(title = "Average Chosen Price vs Income Level",
       subtitle = "Among non-None choices only",
       x = "Income Level", y = "Average Chosen Price (€)") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        axis.text = element_text(color = "black"))

cat("Spearman correlation (income vs avg chosen price):", cor_val, "\n")
cor.test(corr_price_income$income_num, corr_price_income$avg_price,
         method = "spearman")
```

## Multi-Screen Choices vs Shared Account Usage

Do respondents who use shared/family accounts tend to choose plans with more simultaneous screens? We test this by comparing the average number of screens chosen by self-paying subscribers versus shared-account users.

```{r corr-screens-shared}
# Map streams code to numeric screens
streams_numeric <- c(`1` = 1, `2` = 2, `3` = 4)

avg_chosen_streams <- cbc %>%
  filter(choice == 1 & NONE == 0) %>%
  mutate(screens = streams_numeric[as.character(streams_code)]) %>%
  group_by(record_id) %>%
  summarise(avg_screens = mean(screens), .groups = "drop")

corr_streams <- survey_matched %>%
  select(record_id, ott_use) %>%
  filter(!is.na(ott_use) & ott_use != "No") %>%
  mutate(account_type = ifelse(
    grepl("family|friend", ott_use, ignore.case = TRUE),
    "Shared Account", "Self-Paying"
  )) %>%
  inner_join(avg_chosen_streams, by = "record_id")

corr_streams %>%
  ggplot(aes(x = account_type, y = avg_screens, fill = account_type)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.15, alpha = 0.4, size = 2) +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Average Chosen Screens vs Account Type",
       subtitle = "Self-paying subscribers vs shared account users",
       x = "", y = "Average Screens Chosen") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        legend.position = "none",
        axis.text = element_text(color = "black"))

# Wilcoxon test
wt <- wilcox.test(avg_screens ~ account_type, data = corr_streams)
cat("Wilcoxon test p-value:", round(wt$p.value, 4), "\n")

corr_streams %>%
  group_by(account_type) %>%
  summarise(
    N = n(),
    Mean_Screens = round(mean(avg_screens), 2),
    SD = round(sd(avg_screens), 2),
    .groups = "drop"
  ) %>%
  kable(
    caption = "Average Screens Chosen by Account Type",
    col.names = c("Account Type", "N", "Mean Screens", "SD")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

## Education Level vs Subscription Type and Account Sharing

We examine whether Bachelor's-level respondents differ from Master's-level respondents in their subscription behavior (self-paying vs shared) and content preferences.

```{r corr-education-sharing}
edu_sharing <- survey_matched %>%
  filter(!is.na(ott_use) & ott_use != "No" & !is.na(education)) %>%
  mutate(
    edu_level = case_when(
      grepl("High school", education) ~ "High School",
      grepl("Bachelor", education)    ~ "Bachelor's",
      grepl("Master", education)      ~ "Master's"
    ),
    account_type = ifelse(
      grepl("family|friend", ott_use, ignore.case = TRUE),
      "Shared", "Self-Paying"
    )
  ) %>%
  filter(edu_level %in% c("Bachelor's", "Master's"))

# Cross-tabulation
edu_xtab <- table(edu_sharing$edu_level, edu_sharing$account_type)
cat("Education x Account Type:\n")
print(edu_xtab)
cat("\nProportions (row-wise):\n")
print(round(prop.table(edu_xtab, margin = 1) * 100, 1))

# Chi-squared test
chi_test <- chisq.test(edu_xtab, correct = FALSE)
cat("\nChi-squared test p-value:", round(chi_test$p.value, 4), "\n")

# Visualization
edu_sharing %>%
  count(edu_level, account_type) %>%
  group_by(edu_level) %>%
  mutate(pct = round(n / sum(n) * 100, 1)) %>%
  ggplot(aes(x = edu_level, y = pct, fill = account_type)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.8) +
  geom_text(aes(label = paste0(pct, "%")),
    position = position_dodge(0.9), vjust = -0.5, fontface = "bold", size = 4) +
  scale_fill_brewer(palette = "Set2", name = "Account Type") +
  scale_y_continuous(limits = c(0, 80)) +
  labs(title = "Account Type by Education Level",
       subtitle = "Among OTT subscribers only",
       x = "", y = "Percentage (%)") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        legend.position = "bottom",
        axis.text = element_text(color = "black"))
```

```{r corr-education-subscriptions}
# Number of subscriptions by education
edu_subs <- survey_matched %>%
  filter(!is.na(n_subscriptions) & !is.na(education)) %>%
  mutate(edu_level = case_when(
    grepl("High school", education) ~ "High School",
    grepl("Bachelor", education)    ~ "Bachelor's",
    grepl("Master", education)      ~ "Master's"
  )) %>%
  filter(edu_level %in% c("Bachelor's", "Master's"))

edu_subs %>%
  group_by(edu_level) %>%
  summarise(
    N = n(),
    Mean_Subs = round(mean(n_subscriptions), 2),
    SD = round(sd(n_subscriptions), 2),
    .groups = "drop"
  ) %>%
  kable(
    caption = "Number of Subscriptions by Education Level",
    col.names = c("Education", "N", "Mean Subscriptions", "SD")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

# CBC Choice Data Analysis

## Overall Choice Distribution

```{r choice-overall}
none_chosen_pct <- round(
  sum(cbc$choice == 1 & cbc$NONE == 1) / sum(cbc$choice == 1) * 100, 1
)

cbc %>%
  filter(choice == 1) %>%
  mutate(choice_label = ifelse(NONE == 1, "None",
    paste0("Alt ", alt))) %>%
  count(choice_label) %>%
  mutate(pct = round(n / sum(n) * 100, 1)) %>%
  ggplot(aes(x = choice_label, y = pct,
    fill = choice_label)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(pct, "%")),
    vjust = -0.5, fontface = "bold", size = 5) +
  scale_fill_manual(values = c("#4DAF4A", "#377EB8", "#FF7F00", "#E41A1C")) +
  scale_y_continuous(limits = c(0, 40)) +
  labs(title = "Overall Choice Proportions",
       subtitle = paste0("None chosen in ", none_chosen_pct, "% of all tasks"),
       x = "", y = "Percentage (%)") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        legend.position = "none",
        axis.text = element_text(color = "black"))
```

## Cross-tabulations: Price vs Choice

```{r price-xtab}
# Among non-None alternatives, how does choice relate to price?
cbc_real <- cbc %>% filter(NONE == 0)

xtab_price <- xtabs(~ Price + choice, data = cbc_real)
cat("Cross-tabulation: Price x Choice\n")
print(xtab_price)

cat("\nRelative frequency of choices by price level:\n")
rel_freq <- xtabs(choice ~ Price, data = cbc_real) /
  sum(xtabs(choice ~ Price, data = cbc_real))
print(round(rel_freq, 3))
```

```{r price-mosaic}
plot(xtabs(~ Price + choice, data = cbc_real),
     main = "Mosaic Plot: Price vs Choice",
     color = c("lightcoral", "steelblue"))
```

## Cross-tabulation: Ads vs Choice

```{r ads-xtab}
cbc_real <- cbc_real %>%
  mutate(Ads = ads_map[as.character(ads_code)])

cat("Relative frequency of choices by ad level:\n")
rel_freq_ads <- xtabs(choice ~ Ads, data = cbc_real) /
  sum(xtabs(choice ~ Ads, data = cbc_real))
print(round(rel_freq_ads, 3))
```

```{r ads-mosaic}
plot(xtabs(~ Ads + choice, data = cbc_real),
     main = "Mosaic Plot: Ads vs Choice",
     color = c("lightcoral", "steelblue"))
```

# Sample Size Sufficiency

$$N \geq \frac{500 \cdot c}{t \cdot a}$$

```{r sample-size-check}
N <- length(unique(cbc$id))  # 105
c_max <- 5                    # Price has 5 levels
t_tasks <- 10                 # 10 CBC tasks
a_alts <- 3                   # 3 alternatives (excl. None)

required_N <- ceiling(500 * c_max / (t_tasks * a_alts))
actual_ratio <- N * t_tasks * a_alts / c_max

cat("N =", N, "| c =", c_max, "| t =", t_tasks, "| a =", a_alts, "\n")
cat("Minimum N required:", required_N, "\n")
cat("N × t × a / c =", actual_ratio, "(≥ 500 required)\n")
cat("Result:", ifelse(actual_ratio >= 500, "SUFFICIENT", "INSUFFICIENT"), "\n")
```

# Data Preparation for Estimation

Two coding decisions shape the estimation: **effects coding** for categorical attributes and a **linear mean-centered price**.

## Why Effects Coding?

Categorical attributes need numeric encoding. The two standard options are dummy coding (reference = 0) and effects coding (reference = −1). We use effects coding because:

1. **All levels get an explicit part-worth**, including the reference level (recovered as the negative sum of the estimated coefficients). With dummy coding, the reference level's utility is confounded with the intercept.
2. **RAI is straightforward** — we need the full range (max − min) within each attribute, which requires a part-worth for every level.
3. **WTP ratios** ($-\beta_k / \beta_{\text{price}}$) are interpretable for all levels. Under dummy coding the reference level has implicit utility zero, distorting WTP.
4. **None option**: our "None" alternative has all attribute codes set to 0. Under effects coding the reference level is coded −1, so None receives zero contribution from all attribute dummies. The NONE intercept then captures the pure opt-out tendency without confounding with any reference level.

## Why Linear Mean-Centered Price?

Price enters the model as a **single linear parameter** rather than a set of level dummies:

1. **Parsimony** — one coefficient instead of four captures the expected negative price–utility relationship.
2. **Mean-centering** — subtracting the mean price ($\bar{p} = €10.19$) keeps price orthogonal to the intercept. The None option gets price = 0.
3. **WTP** — a linear price coefficient feeds directly into $\text{WTP}_k = -\beta_k / \beta_{\text{price}}$, giving euros per month.

## Effects Coding Functions

```{r helper-functions}
# Effects coding: reference level coded as -1 (not 0)
effects_coding <- function(.data, vars, none = FALSE) {
  variables <- names(dplyr::select(.data, {{ vars }}))
  ws <- .data

  if (isTRUE(none)) {
    none_ws <- filter(ws, apply(ws[variables], 1, sum) == 0)
    ws <- filter(ws, apply(ws[variables], 1, sum) != 0)
  }

  for (a in variables) {
    current <- names(ws)
    ws <- ws %>%
      fastDummies::dummy_cols(select_columns = a, remove_first_dummy = TRUE)
    helper <- setdiff(names(ws), current)
    ws[["del"]] <- apply(ws[helper], 1, sum)
    ws <- ws %>%
      mutate(across(all_of(helper), ~ ifelse(del == 0, -1, .x)), del = NULL)
  }

  if (isTRUE(none)) {
    mis_names <- setdiff(names(ws), names(none_ws))
    none_ws[mis_names] <- 0
    ws <- rbind(ws, none_ws)
  }
  return(ws)
}

# Mean-center price (excluding None)
mc_price <- function(.data, price) {
  price_var <- dplyr::select(.data, {{ price }}) %>% pull()
  mw <- mean(price_var[price_var != 0])
  price_mc <- ifelse(price_var != 0, price_var - mw, 0)
  .data %>% mutate(price_mc = price_mc)
}

# Numerically stable MNL probability
log_sum_exp <- function(x) {
  cc <- max(x)
  cc + log(sum(exp(x - cc)))
}

mnl_prob <- function(x) {
  exp(x - log_sum_exp(x))
}
```

## Construct Estimation Dataset

```{r construct-estimation-data}
# The design data already has integer-coded attributes.
# We convert to the format needed for effects coding.
cbc_clean <- cbc %>%
  select(id, record_id, task, alt, choice, NONE,
         ads_code, quality_code, streams_code, content_code, Price) %>%
  rename(ads = ads_code, quality = quality_code,
         streams = streams_code, content = content_code) %>%
  # For NONE rows, set attribute codes to 0 (already the case)
  mutate(across(c(ads, quality, streams, content), ~ ifelse(NONE == 1, 0L, .x)))

# Apply effects coding to categorical attributes
cbc_eff <- cbc_clean %>%
  effects_coding(vars = c(ads, quality, streams, content), none = TRUE) %>%
  arrange(id, task, alt) %>%
  mc_price(Price) %>%
  mutate(obs = cumsum(c(1, diff(task) != 0 | diff(id) != 0)))

# Preview
cbc_eff %>%
  filter(id == 1) %>%
  head(8)
```

> Each non-None alternative is represented by 8 effects-coded dummies (2 per categorical attribute), 1 mean-centered price, and 1 NONE indicator — 10 parameters total. For the None alternative all columns are 0 except NONE = 1.

# MNL Estimation (Homogeneous Preferences)

## MNL Model: Full Specification

We estimate a multinomial logit model with:

- **Effects-coded dummies** for Ads, Video Quality, Simultaneous Streams, and Content Type
- **Linear (mean-centered) price** — a single parameter
- **NONE intercept** — captures the baseline tendency to opt out

```{r mnl-dfidx}
choice_data <- dfidx(
  cbc_eff,
  shape = "long",
  choice = "choice",
  idx = c("obs", "alt")
)
```

```{r mnl-full}
mnl1 <- mlogit(
  choice ~ 0 +
    NONE +
    ads_2 + ads_3 +
    quality_2 + quality_3 +
    streams_2 + streams_3 +
    content_2 + content_3 +
    price_mc,
  data = choice_data
)

summary(mnl1)
```

## MNL Model: Restricted (Price Only)

```{r mnl-restricted}
mnl0 <- mlogit(
  choice ~ 0 + NONE + price_mc,
  data = choice_data
)
```

## Likelihood Ratio Test

```{r lr-test}
lrtest(mnl0, mnl1)
```

The full model significantly outperforms the price-only model, so the non-price attributes add real explanatory power.

# Part-Worth Utilities

## Compute Part-Worths (Mean-Centered from Effects Coding)

With effects coding, the estimated coefficients are already deviations from the attribute mean. The omitted reference levels have part-worth equal to the negative sum of the included levels.

```{r partworth-compute}
coefs <- coef(mnl1)

# Build part-worth table
# Effects coding: reference = -sum(included levels)
pw_df <- data.frame(
  var = c(
    "NONE",
    "With Ads", "Limited Ads", "Ad-free",
    "HD 720p", "Full HD 1080p", "4K HDR",
    "1 screen", "2 screens", "4 screens",
    "Licensed Only", "Originals & Licensed", "Exclusive Originals",
    "Price (per €1)"
  ),
  attr = c(
    "",
    rep("Ads", 3),
    rep("Video Quality", 3),
    rep("Simultaneous Streams", 3),
    rep("Content Type", 3),
    "Price"
  ),
  est = c(
    coefs["NONE"],
    # Ads: ref = With Ads = -(ads_2 + ads_3)
    -(coefs["ads_2"] + coefs["ads_3"]),
    coefs["ads_2"],
    coefs["ads_3"],
    # Quality: ref = HD 720p = -(quality_2 + quality_3)
    -(coefs["quality_2"] + coefs["quality_3"]),
    coefs["quality_2"],
    coefs["quality_3"],
    # Streams: ref = 1 screen = -(streams_2 + streams_3)
    -(coefs["streams_2"] + coefs["streams_3"]),
    coefs["streams_2"],
    coefs["streams_3"],
    # Content: ref = Licensed Only = -(content_2 + content_3)
    -(coefs["content_2"] + coefs["content_3"]),
    coefs["content_2"],
    coefs["content_3"],
    # Price
    coefs["price_mc"]
  ),
  order = 1:14
)
rownames(pw_df) <- NULL

pw_df %>%
  mutate(est = round(est, 4)) %>%
  kable(
    caption = "MNL Part-Worth Utilities (Effects Coding)",
    col.names = c("Level", "Attribute", "Part-Worth", "Order")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  collapse_rows(columns = 2, valign = "top")
```

## Part-Worth Utility Plot

```{r partworth-plot, fig.height=5}
pw_df %>%
  filter(attr != "" & attr != "Price") %>%
  ggplot(aes(x = reorder(var, order), y = est, group = attr)) +
  geom_point(size = 3, color = "steelblue") +
  geom_line(color = "steelblue", linewidth = 0.8) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "darkblue") +
  facet_wrap(~attr, scales = "free_x") +
  labs(title = "Part-Worth Utilities (MNL)",
       x = "Attribute Levels", y = "Part-Worth Utility") +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.text.x = element_text(angle = 35, hjust = 1, size = 9),
    axis.text = element_text(color = "black"),
    strip.text = element_text(face = "bold")
  )
```

# Relative Attribute Importance (RAI)

The importance of each attribute is computed as the range of its part-worth utilities divided by the sum of all ranges.

$$\text{RAI}_k = \frac{\max(\text{PW}_k) - \min(\text{PW}_k)}{\sum_{k=1}^{K} [\max(\text{PW}_k) - \min(\text{PW}_k)]} \times 100$$

For price (linear specification), the range is $|\beta_{\text{price}}| \times (\text{Price}_{max} - \text{Price}_{min})$.

```{r rai-compute}
price_range <- (14.99 - 4.99) * abs(coefs["price_mc"])

RAI <- pw_df %>%
  filter(attr != "" & attr != "Price") %>%
  group_by(attr) %>%
  summarise(range = max(est) - min(est), .groups = "drop") %>%
  rbind(data.frame(attr = "Price", range = as.numeric(price_range))) %>%
  mutate(RAI = round(range / sum(range) * 100, 1)) %>%
  arrange(desc(RAI))

RAI %>%
  kable(
    caption = "Relative Attribute Importance (MNL)",
    col.names = c("Attribute", "Range", "RAI (%)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r rai-plot}
ggplot(RAI, aes(x = reorder(attr, RAI), y = RAI,
                label = paste0(RAI, "%"))) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.8) +
  geom_text(hjust = -0.2, fontface = "bold", size = 4.5) +
  coord_flip() +
  scale_y_continuous(limits = c(0, max(RAI$RAI) * 1.2),
                     breaks = seq(0, 50, 10)) +
  labs(title = "Relative Attribute Importance (MNL)",
       x = "", y = "RAI (%)") +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.title = element_text(face = "bold"),
    axis.text = element_text(color = "black")
  )
```

# Willingness-to-Pay (WTP)

$$\text{WTP}_k = \frac{-\beta_k}{\beta_{\text{price}}}$$

```{r wtp-compute}
# WTP for all non-price attribute levels
wtp_df <- pw_df %>%
  filter(attr != "" & attr != "Price") %>%
  mutate(
    WTP = round(-est / coefs["price_mc"], 2)
  )

wtp_df %>%
  select(attr, var, est, WTP) %>%
  kable(
    caption = "Willingness-to-Pay (€) for Non-Price Attribute Levels",
    col.names = c("Attribute", "Level", "Part-Worth", "WTP (€)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  collapse_rows(columns = 1, valign = "top")
```

```{r wtp-gmnl}
# Cross-check with gmnl package
wtp.gmnl(mnl1, wrt = "price_mc")
```

```{r wtp-plot, fig.height=5}
wtp_df %>%
  ggplot(aes(x = reorder(var, WTP), y = WTP, fill = attr)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_text(aes(label = paste0("€", WTP)),
    hjust = ifelse(wtp_df$WTP >= 0, -0.1, 1.1),
    fontface = "bold", size = 3.5) +
  coord_flip() +
  scale_fill_brewer(palette = "Set2", name = "Attribute") +
  labs(title = "Willingness-to-Pay by Attribute Level",
       x = "", y = "WTP (€)") +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.text = element_text(color = "black"),
    legend.position = "bottom"
  )
```

# Hierarchical Bayes MNL (Heterogeneous Preferences)

The HB-MNL model estimates individual-level part-worths, allowing us to account for preference heterogeneity across respondents.

## Prepare Data for ChoiceModelR

```{r hb-prepare}
# Create the choices vector (ChoiceModelR format)
indexes <- cbc_eff %>%
  group_by(id, task) %>%
  reframe(
    ch = alt[choice == 1],
    no = max(alt)
  )

choices_vec <- unname(unlist(purrr::map(seq.int(nrow(indexes)), function(x) {
  c(indexes$ch[x], rep(0, times = indexes$no[x] - 1))
})))

# Build design matrix
dm <- cbc_eff %>%
  mutate(choices = choices_vec) %>%
  select(id, task, alt,
         ads_2, ads_3,
         quality_2, quality_3,
         streams_2, streams_3,
         content_2, content_3,
         price_mc, NONE, choices) %>%
  as.data.frame() %>%
  mutate(task = cumsum(c(1, diff(alt) < 0)), .by = id)

# Number of parameters (everything except id, task, alt, choices)
n_params <- ncol(dm) - 4
cat("Parameters to estimate:", n_params, "\n")
cat("Design matrix dimensions:", nrow(dm), "x", ncol(dm), "\n")
```

## Run HB-MNL

```{r hb-estimate, results='hide'}
dir.create("hbmnl", showWarnings = FALSE)

set.seed(42)
hb_out <- choicemodelr(
  data = dm,
  xcoding = rep(1, times = n_params),
  mcmc = list(R = 20000, use = 10000),
  options = list(none = FALSE, save = TRUE, keep = 10),
  directory = "hbmnl"
)
```

## Extract Individual-Level Estimates

```{r hb-extract}
# Beta point estimates: mean across MCMC draws for each individual
betas_ind <- apply(hb_out$betadraw, c(1, 2), mean)

# Column names match the order in dm
param_names <- c("ads_2", "ads_3", "quality_2", "quality_3",
                 "streams_2", "streams_3", "content_2", "content_3",
                 "price_mc", "NONE")
colnames(betas_ind) <- param_names

cat("Individual betas matrix:", nrow(betas_ind), "respondents x",
    ncol(betas_ind), "parameters\n")
```

## HB Part-Worth Utilities (Means and SDs)

```{r hb-partworths}
# Population-level means and SDs
hb_means <- colMeans(betas_ind)
hb_sds   <- apply(betas_ind, 2, sd)

# Reconstruct reference levels
hb_pw <- data.frame(
  var = c(
    "With Ads", "Limited Ads", "Ad-free",
    "HD 720p", "Full HD 1080p", "4K HDR",
    "1 screen", "2 screens", "4 screens",
    "Licensed Only", "Originals & Licensed", "Exclusive Originals",
    "Price (per €1)", "NONE"
  ),
  attr = c(
    rep("Ads", 3), rep("Video Quality", 3),
    rep("Simultaneous Streams", 3), rep("Content Type", 3),
    "Price", ""
  ),
  Mean = c(
    -(hb_means["ads_2"] + hb_means["ads_3"]),
    hb_means["ads_2"], hb_means["ads_3"],
    -(hb_means["quality_2"] + hb_means["quality_3"]),
    hb_means["quality_2"], hb_means["quality_3"],
    -(hb_means["streams_2"] + hb_means["streams_3"]),
    hb_means["streams_2"], hb_means["streams_3"],
    -(hb_means["content_2"] + hb_means["content_3"]),
    hb_means["content_2"], hb_means["content_3"],
    hb_means["price_mc"],
    hb_means["NONE"]
  ),
  SD = c(
    # For reference levels, compute SD of -(ind_ads_2 + ind_ads_3)
    sd(-(betas_ind[, "ads_2"] + betas_ind[, "ads_3"])),
    hb_sds["ads_2"], hb_sds["ads_3"],
    sd(-(betas_ind[, "quality_2"] + betas_ind[, "quality_3"])),
    hb_sds["quality_2"], hb_sds["quality_3"],
    sd(-(betas_ind[, "streams_2"] + betas_ind[, "streams_3"])),
    hb_sds["streams_2"], hb_sds["streams_3"],
    sd(-(betas_ind[, "content_2"] + betas_ind[, "content_3"])),
    hb_sds["content_2"], hb_sds["content_3"],
    hb_sds["price_mc"],
    hb_sds["NONE"]
  )
)

hb_pw %>%
  mutate(Mean = round(Mean, 4), SD = round(SD, 4)) %>%
  kable(
    caption = "HB-MNL Part-Worth Utilities: Population Means and SDs",
    col.names = c("Level", "Attribute", "Mean", "SD")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  collapse_rows(columns = 2, valign = "top")
```

## HB Relative Attribute Importance

```{r hb-rai}
# Compute RAI at the individual level, then average
compute_individual_rai <- function(beta_row) {
  # Reconstruct part-worths for each attribute
  ads_pw <- c(-(beta_row["ads_2"] + beta_row["ads_3"]),
              beta_row["ads_2"], beta_row["ads_3"])
  quality_pw <- c(-(beta_row["quality_2"] + beta_row["quality_3"]),
                  beta_row["quality_2"], beta_row["quality_3"])
  streams_pw <- c(-(beta_row["streams_2"] + beta_row["streams_3"]),
                  beta_row["streams_2"], beta_row["streams_3"])
  content_pw <- c(-(beta_row["content_2"] + beta_row["content_3"]),
                  beta_row["content_2"], beta_row["content_3"])
  price_range_i <- abs(beta_row["price_mc"]) * (14.99 - 4.99)

  ranges <- c(
    Price = as.numeric(price_range_i),
    Ads = diff(range(ads_pw)),
    `Video Quality` = diff(range(quality_pw)),
    `Simultaneous Streams` = diff(range(streams_pw)),
    `Content Type` = diff(range(content_pw))
  )
  ranges / sum(ranges) * 100
}

rai_individual <- t(apply(betas_ind, 1, compute_individual_rai))

rai_hb <- data.frame(
  Attribute = colnames(rai_individual),
  Mean = round(colMeans(rai_individual), 1),
  SD = round(apply(rai_individual, 2, sd), 1)
) %>%
  arrange(desc(Mean))

rai_hb %>%
  kable(
    caption = "HB-MNL Relative Attribute Importance: Means and SDs",
    col.names = c("Attribute", "Mean RAI (%)", "SD (%)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r hb-rai-plot}
ggplot(rai_hb, aes(x = reorder(Attribute, Mean), y = Mean,
                   label = paste0(Mean, "%"))) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.8) +
  geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD),
    width = 0.3, color = "grey30") +
  geom_text(hjust = -0.3, fontface = "bold", size = 4.5) +
  coord_flip() +
  scale_y_continuous(limits = c(0, max(rai_hb$Mean + rai_hb$SD) * 1.15),
                     breaks = seq(0, 60, 10)) +
  labs(title = "Relative Attribute Importance (HB-MNL)",
       subtitle = "Error bars show ±1 SD across respondents",
       x = "", y = "RAI (%)") +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold"),
    axis.text = element_text(color = "black")
  )
```

```{r hb-rai-boxplot}
as.data.frame(rai_individual) %>%
  pivot_longer(everything(), names_to = "Attribute", values_to = "RAI") %>%
  ggplot(aes(x = reorder(Attribute, RAI, FUN = median), y = RAI, fill = Attribute)) +
  geom_boxplot(alpha = 0.7) +
  coord_flip() +
  scale_fill_brewer(palette = "Set2") +
  labs(title = "Distribution of Individual Attribute Importance (HB-MNL)",
       x = "", y = "RAI (%)") +
  theme_bw(base_size = 14) +
  theme(plot.title = element_text(face = "bold"),
        legend.position = "none",
        axis.text = element_text(color = "black"))
```

## HB Willingness-to-Pay

```{r hb-wtp}
# Individual-level WTP: -beta_k / beta_price for each respondent
wtp_individual <- data.frame(
  # Ads
  `With Ads`           = -(-(betas_ind[,"ads_2"] + betas_ind[,"ads_3"])) / betas_ind[,"price_mc"],
  `Limited Ads`        = -betas_ind[,"ads_2"] / betas_ind[,"price_mc"],
  `Ad-free`            = -betas_ind[,"ads_3"] / betas_ind[,"price_mc"],
  # Quality
  `HD 720p`            = -(-(betas_ind[,"quality_2"] + betas_ind[,"quality_3"])) / betas_ind[,"price_mc"],
  `Full HD 1080p`      = -betas_ind[,"quality_2"] / betas_ind[,"price_mc"],
  `4K HDR`             = -betas_ind[,"quality_3"] / betas_ind[,"price_mc"],
  # Streams
  `1 screen`           = -(-(betas_ind[,"streams_2"] + betas_ind[,"streams_3"])) / betas_ind[,"price_mc"],
  `2 screens`          = -betas_ind[,"streams_2"] / betas_ind[,"price_mc"],
  `4 screens`          = -betas_ind[,"streams_3"] / betas_ind[,"price_mc"],
  # Content
  `Licensed Only`      = -(-(betas_ind[,"content_2"] + betas_ind[,"content_3"])) / betas_ind[,"price_mc"],
  `Originals & Licensed` = -betas_ind[,"content_2"] / betas_ind[,"price_mc"],
  `Exclusive Originals`  = -betas_ind[,"content_3"] / betas_ind[,"price_mc"],
  check.names = FALSE
)

wtp_summary <- data.frame(
  Level = names(wtp_individual),
  Attribute = c(rep("Ads", 3), rep("Video Quality", 3),
                rep("Simultaneous Streams", 3), rep("Content Type", 3)),
  Mean_WTP = round(colMeans(wtp_individual), 2),
  SD_WTP = round(apply(wtp_individual, 2, sd), 2)
)
rownames(wtp_summary) <- NULL

wtp_summary %>%
  kable(
    caption = "HB-MNL Willingness-to-Pay (€): Means and SDs",
    col.names = c("Level", "Attribute", "Mean WTP (€)", "SD (€)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  collapse_rows(columns = 2, valign = "top")
```

# Holdout Task Validation

We assess predictive validity using a **holdout task** — a fixed choice set shown to all respondents but excluded from estimation.

## Holdout Task Profiles

```{r holdout-profiles}
holdout_profiles <- data.frame(
  Alternative = c("A", "B", "C", "None"),
  Price = c(7.99, 12.99, 4.99, 0),
  Ads = c("Limited Ads", "Ad-free", "With Ads", "-"),
  Quality = c("Full HD 1080p", "4K HDR", "HD 720p", "-"),
  Streams = c("2 screens", "4 screens", "1 screen", "-"),
  Content = c("Originals & Licensed", "Exclusive Originals", "Licensed Only", "-")
)

holdout_profiles %>%
  kable(caption = "Holdout Task: Product Profiles") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

## Compute Predicted Utilities (HB Individual-Level)

```{r holdout-design}
# Mean-centered prices for holdout
mw_price <- mean(cbc$Price[cbc$Price != 0])

# Holdout design matrix (effects coding)
holdout_dm <- data.frame(
  ads_2    = c( 1, -1, -1, 0),   # Limited Ads / Ad-free / With Ads / None
  ads_3    = c(-1,  1, -1, 0),
  quality_2 = c( 1, -1, -1, 0),  # Full HD / 4K / HD 720p / None
  quality_3 = c(-1,  1, -1, 0),
  streams_2 = c( 1, -1, -1, 0),  # 2 screens / 4 screens / 1 screen / None
  streams_3 = c(-1,  1, -1, 0),
  content_2 = c( 1, -1, -1, 0),  # Orig&Lic / ExclOrig / Licensed / None
  content_3 = c(-1,  1, -1, 0),
  price_mc  = c(7.99 - mw_price, 12.99 - mw_price, 4.99 - mw_price, 0),
  NONE      = c(0, 0, 0, 1)
)
```

```{r holdout-predict}
# Individual-level utilities for holdout alternatives
holdout_utils <- as.data.frame(betas_ind %*% t(as.matrix(holdout_dm))) %>%
  setNames(c("A", "B", "C", "None"))

# Actual choices from survey
holdout_actual <- survey_matched %>%
  mutate(
    holdout_choice = case_when(
      grepl("€7.99", holdout)  ~ 1L,
      grepl("€12.99", holdout) ~ 2L,
      grepl("€4.99", holdout)  ~ 3L,
      TRUE                     ~ 4L
    )
  ) %>%
  pull(holdout_choice)

holdout_utils[["actual"]] <- holdout_actual
```

## Hit Rate

```{r hit-rate}
predicted_choice <- apply(holdout_utils[, 1:4], 1, which.max)
hit_rate <- round(sum(predicted_choice == holdout_utils$actual) /
                    nrow(holdout_utils) * 100, 2)

cat("Hit Rate:", hit_rate, "%\n")
cat("(Chance level: 25%)\n")
```

## Mean Hit Probability

```{r mean-hit-prob}
# Choice probabilities per respondent
ch_probs <- as.data.frame(t(apply(holdout_utils[, 1:4], 1, mnl_prob)))
names(ch_probs) <- c("A", "B", "C", "None")

# Probability assigned to the actually chosen alternative
ch_probs[["actual_label"]] <- c("A", "B", "C", "None")[holdout_utils$actual]

mean_hit_prob <- ch_probs %>%
  rowwise() %>%
  mutate(hit_prob = get(actual_label)) %>%
  ungroup() %>%
  summarise(mhp = mean(hit_prob) * 100) %>%
  pull(mhp) %>%
  round(2)

cat("Mean Hit Probability:", mean_hit_prob, "%\n")
cat("(Chance level: 25%)\n")
```

## Mean Absolute Error (MAE)

```{r mae}
# Actual choice shares
actual_shares <- sapply(1:4, function(x) {
  sum(holdout_utils$actual == x)
}) / nrow(holdout_utils)

# Predicted choice shares (mean probabilities)
predicted_shares <- colMeans(ch_probs[, 1:4])

mae <- round(mean(abs(actual_shares - predicted_shares)) * 100, 2)

# Summary table
data.frame(
  Alternative = c("A", "B", "C", "None"),
  Actual = round(actual_shares * 100, 1),
  Predicted = round(predicted_shares * 100, 1),
  AbsError = round(abs(actual_shares - predicted_shares) * 100, 1)
) %>%
  kable(
    caption = "Holdout Validation: Actual vs Predicted Choice Shares (%)",
    col.names = c("Alternative", "Actual (%)", "Predicted (%)", "|Error| (%)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

cat("Mean Absolute Error:", mae, "%\n")
```

## Validation Summary

```{r validation-summary}
data.frame(
  Metric = c("Hit Rate", "Mean Hit Probability", "Mean Absolute Error"),
  Value = c(
    paste0(hit_rate, "%"),
    paste0(mean_hit_prob, "%"),
    paste0(mae, "%")
  ),
  Benchmark = c("25% (chance)", "25% (chance)", "0% (perfect)")
) %>%
  kable(caption = "Predictive Validation Summary") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

# Subgroup Analysis

## Attribute Importance by Gender

```{r rai-by-gender}
# Map individual RAI to respondents
rai_with_demo <- as.data.frame(rai_individual)
rai_with_demo$record_id <- unique(cbc$record_id)

rai_gender <- rai_with_demo %>%
  left_join(survey_matched %>% select(record_id, gender), by = "record_id") %>%
  filter(!is.na(gender)) %>%
  pivot_longer(cols = -c(record_id, gender),
               names_to = "Attribute", values_to = "RAI") %>%
  group_by(gender, Attribute) %>%
  summarise(Mean = round(mean(RAI), 1), SD = round(sd(RAI), 1), .groups = "drop")

rai_gender %>%
  pivot_wider(names_from = gender, values_from = c(Mean, SD)) %>%
  kable(caption = "Attribute Importance by Gender (HB-MNL)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r rai-gender-plot}
rai_gender %>%
  ggplot(aes(x = Attribute, y = Mean, fill = gender)) +
  geom_bar(stat = "identity", position = position_dodge(0.8),
           alpha = 0.8, width = 0.7) +
  geom_errorbar(aes(ymin = Mean - SD, ymax = Mean + SD),
    position = position_dodge(0.8), width = 0.3) +
  scale_fill_brewer(palette = "Set2", name = "Gender") +
  labs(title = "Attribute Importance by Gender",
       x = "", y = "RAI (%)") +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "bottom",
    axis.text = element_text(color = "black"),
    axis.text.x = element_text(angle = 20, hjust = 1)
  )
```

## Attribute Importance by OTT Usage

```{r rai-by-ott}
rai_ott <- rai_with_demo %>%
  left_join(survey_matched %>% select(record_id, ott_use), by = "record_id") %>%
  filter(!is.na(ott_use)) %>%
  mutate(ott_group = ifelse(ott_use == "No", "Non-user", "User")) %>%
  pivot_longer(cols = -c(record_id, ott_use, ott_group),
               names_to = "Attribute", values_to = "RAI") %>%
  group_by(ott_group, Attribute) %>%
  summarise(Mean = round(mean(RAI), 1), SD = round(sd(RAI), 1), .groups = "drop")

rai_ott %>%
  pivot_wider(names_from = ott_group, values_from = c(Mean, SD)) %>%
  kable(caption = "Attribute Importance by OTT Usage (HB-MNL)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

# Market Simulation

We simulate market shares for five product configurations that represent different positioning strategies in the OTT market.

## Define Product Scenarios

```{r define-products}
# Product configurations (effects coded)
# Coding reminder:
#   ads: ref=With Ads(1), Limited Ads(2), Ad-free(3)
#   quality: ref=HD 720p(1), Full HD(2), 4K+HDR(3)
#   streams: ref=1 screen(1), 2 screens(2), 4 screens(3)
#   content: ref=Licensed(1), Orig&Lic(2), Exclusive(3)
# Effects coding: included level=1, ref level=-1 for both dummies

products <- data.frame(
  Name = c(
    "Budget Basic",
    "Mid-Tier (Netflix Standard)",
    "Premium All-In",
    "Ad-Supported Value",
    "Family Plan",
    "None (Opt-out)"
  ),
  Description = c(
    "Cheapest, ads, basic quality, 1 screen, licensed",
    "Mid-price, limited ads, Full HD, 2 screens, mixed content",
    "Top-tier, ad-free, 4K, 4 screens, exclusive originals",
    "Low price, with ads, Full HD, 2 screens, mixed content",
    "Mid-high price, ad-free, Full HD, 4 screens, mixed content",
    "Consumer opts out of all options"
  ),
  # Effects-coded dummies
  ads_2     = c(-1,  1, -1, -1, -1, 0),
  ads_3     = c(-1, -1,  1, -1,  1, 0),
  quality_2 = c(-1,  1, -1,  1,  1, 0),
  quality_3 = c(-1, -1,  1, -1, -1, 0),
  streams_2 = c(-1,  1, -1,  1, -1, 0),
  streams_3 = c(-1, -1,  1, -1,  1, 0),
  content_2 = c(-1,  1, -1,  1,  1, 0),
  content_3 = c(-1, -1,  1, -1, -1, 0),
  price_mc  = c(4.99, 9.99, 14.99, 7.99, 12.99, 0) - mw_price,
  NONE      = c(0, 0, 0, 0, 0, 1),
  stringsAsFactors = FALSE
)

products %>%
  select(Name, Description) %>%
  mutate(
    Price = c("€4.99", "€9.99", "€14.99", "€7.99", "€12.99", "-"),
    Ads = c("With Ads", "Limited Ads", "Ad-free", "With Ads", "Ad-free", "-"),
    Quality = c("HD 720p", "Full HD", "4K HDR", "Full HD", "Full HD", "-"),
    Streams = c("1", "2", "4", "2", "4", "-"),
    Content = c("Licensed", "Orig & Lic", "Exclusive", "Orig & Lic", "Orig & Lic", "-")
  ) %>%
  kable(caption = "Market Simulation: Product Configurations") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

## MNL Market Shares (Aggregate-Level)

```{r mnl-market-shares}
# Design matrix for products
products_matrix <- as.matrix(products[, c("ads_2", "ads_3", "quality_2", "quality_3",
  "streams_2", "streams_3", "content_2", "content_3", "price_mc", "NONE")])

# Aggregate utility from MNL
utility_mnl <- as.vector(products_matrix %*% coef(mnl1))

# Market shares (MNL logit rule)
shares_mnl <- mnl_prob(utility_mnl) * 100

mnl_sim <- data.frame(
  Product = products$Name,
  Utility = round(utility_mnl, 3),
  Share = round(shares_mnl, 1)
)

mnl_sim %>%
  kable(
    caption = "MNL Market Simulation Results",
    col.names = c("Product", "Utility", "Market Share (%)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

## HB-MNL Market Shares (Individual-Level)

```{r hb-market-shares}
# Individual-level utilities for each product
ind_utilities <- betas_ind %*% t(products_matrix)
colnames(ind_utilities) <- products$Name

# Individual choice probabilities
ind_probs <- t(apply(ind_utilities, 1, mnl_prob))
colnames(ind_probs) <- products$Name

# Average market shares
shares_hb <- colMeans(ind_probs) * 100
shares_hb_sd <- apply(ind_probs, 2, sd) * 100

hb_sim <- data.frame(
  Product = products$Name,
  Mean_Share = round(shares_hb, 1),
  SD_Share = round(shares_hb_sd, 1)
)

hb_sim %>%
  kable(
    caption = "HB-MNL Market Simulation Results",
    col.names = c("Product", "Mean Share (%)", "SD (%)")
  ) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

```{r sim-comparison}
comparison <- data.frame(
  Product = products$Name,
  MNL = round(shares_mnl, 1),
  HB = round(shares_hb, 1)
) %>%
  pivot_longer(cols = c(MNL, HB), names_to = "Model", values_to = "Share")

comparison %>%
  ggplot(aes(x = reorder(Product, -Share), y = Share, fill = Model)) +
  geom_bar(stat = "identity", position = position_dodge(0.8),
           alpha = 0.8, width = 0.7) +
  geom_text(aes(label = paste0(Share, "%")),
    position = position_dodge(0.8), vjust = -0.5, size = 3.5, fontface = "bold") +
  scale_fill_manual(values = c("MNL" = "steelblue", "HB" = "coral")) +
  scale_y_continuous(limits = c(0, max(comparison$Share) * 1.2)) +
  labs(title = "Market Shares: MNL vs HB-MNL",
       x = "", y = "Market Share (%)") +
  theme_bw(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "bottom",
    axis.text = element_text(color = "black"),
    axis.text.x = element_text(angle = 20, hjust = 1)
  )
```

## Scenario: What If We Remove the Family Plan?

The Family Plan captures the largest market share. What happens to the remaining products if a competitor discontinues this offering — or if it is not available in a given market?

```{r scenario-no-family}
# Remove "Family Plan" (product 5)
products_reduced <- products[-5, ]
products_matrix_red <- as.matrix(products_reduced[,
  c("ads_2", "ads_3", "quality_2", "quality_3",
    "streams_2", "streams_3", "content_2", "content_3", "price_mc", "NONE")])

ind_utils_red <- betas_ind %*% t(products_matrix_red)
ind_probs_red <- t(apply(ind_utils_red, 1, mnl_prob))

shares_red <- round(colMeans(ind_probs_red) * 100, 1)

data.frame(
  Product = products_reduced$Name,
  `With Family Plan` = round(shares_hb[-5], 1),
  `Without Family Plan` = shares_red,
  Change = round(shares_red - shares_hb[-5], 1),
  check.names = FALSE
) %>%
  kable(caption = "Scenario: Market Shares Without Family Plan (HB-MNL)") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

# Discussion and Managerial Implications

## Key Findings

```{r findings-table}
data.frame(
  Finding = c(
    "Price dominates choice",
    "Ads are the second-most important attribute",
    "Content mix beats exclusivity",
    "Quality and streams are secondary",
    "Moderate opt-out rate",
    "Substantial preference heterogeneity"
  ),
  Detail = c(
    "Price is the most important attribute, consistent with the price-sensitive profile of our sample.",
    "Ad-free is strongly preferred; WTP for removing ads is among the highest across all attributes.",
    "'Originals & Licensed' is preferred over 'Licensed Only' and 'Exclusive Originals'. A mixed catalog resonates better than exclusivity alone.",
    "Video Quality and Simultaneous Streams each account for roughly 13-16% of importance.",
    paste0(none_chosen_pct, "% of choices were 'None', suggesting most respondents would subscribe if the offering is reasonable."),
    "Large SDs in individual RAI scores show that preferences vary considerably across respondents."
  )
) %>%
  kable(caption = "Summary of Key Findings") %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

## Managerial Implications

1. **Tiered pricing matters.** Price sensitivity dominates choice. Platforms should maintain a clear tier ladder — a budget entry point (~€5), a mid-tier (~€8-10), and a feature-rich option at higher price.

2. **Ad-free commands a premium.** Consumers value ad removal almost as much as the price itself. Higher-priced ad-free tiers are justified by the data.

3. **Content breadth over exclusivity.** "Originals & Licensed" is consistently the top content preference. Over-investing in exclusive originals at the expense of a broad catalog does not pay off.

4. **The "Family Plan" works.** An ad-free, multi-screen, mixed-content offering at €12.99 dominates the simulation with the highest share, driven by shared household viewing.

5. **Budget tiers need substance.** A low price with ads, basic quality, and limited content loses to mid-tier options and even to opt-out. The cheapest tier must still deliver on content.

6. **Preferences vary across respondents.** The large SDs in individual-level RAI suggest different consumer segments respond to different positioning — some are price-driven, others prioritize ad-free or content quality.

## Limitations

- **Convenience sample:** Predominantly young students — results may not generalize to older or more diverse populations.
- **Hypothetical bias:** Stated preferences can differ from actual purchase behavior.
- **No brand effects:** The unlabeled CBC design ignores brand equity (Netflix, Disney+, etc.), which plays a major role in real decisions.
- **One respondent excluded:** One respondent was in the survey but absent from the design export, leaving 105 of 106 in the analysis.
